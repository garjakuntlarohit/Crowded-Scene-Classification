# -*- coding: utf-8 -*-
"""CrowdedSceneClassification_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IB4lkU3cNxQRURJx0BM2lT8fdDcJ31XA
"""

# pip install ultralytics

# ------------------------
# Import Libraries
# ------------------------
import tensorflow as tf
import numpy as np
import pandas as pd
import seaborn as sns
import cv2
import random
import matplotlib.pyplot as plt
import os
from ultralytics import YOLO
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

import warnings
warnings.filterwarnings("ignore")

img_path = 'D:/archive/images.npy'

# Load images
img = np.load('D:/archive/images.npy')
print(f"Loaded {img.shape[0]} images")

# YOLO model
model = YOLO('yolov8m.pt')  # Balanced accuracy vs speed

# Clean images â€” ensure same shape (480, 640, 3) and uint8
expected_shape = (480, 640, 3)
cleaned_images = []
valid_indices = []

for idx, im in enumerate(img):
    if im.shape == expected_shape and im.dtype == np.uint8:
        cleaned_images.append(im)
        valid_indices.append(idx)
    else:
        print(f"Skipping image {idx}: shape {im.shape}, dtype {im.dtype}")

# Batch predict
batch_size = 8
results_list = []

for i in range(0, len(cleaned_images), batch_size):
    batch = cleaned_images[i:i+batch_size]
    results = model.predict(source=batch, classes=[0], conf=0.25, imgsz=960, verbose=False)

    for j, r in enumerate(results):
        boxes = r.boxes.xyxy.cpu().numpy()
        people_count = len(boxes)
        true_idx = valid_indices[i + j]  # original image index
        results_list.append({'image_id': true_idx, 'people_detected': people_count})

    print(f"Processed {min(i + batch_size, len(cleaned_images))}/{len(cleaned_images)} images")

# Save CSV
df = pd.DataFrame(results_list)
csv_path = 'people_counts.csv'
df.to_csv(csv_path, index=False)
print(f"\n People counts saved to: {csv_path}")

# Step 1: Load CSV
csv_path = 'people_counts.csv'
label_df = pd.read_csv(csv_path)
label_df.columns = ['id', 'people']  # Ensure consistent column names

# Step 2: Convert 'people' column to NumPy array
labels = np.array(label_df['people'], dtype=np.int32)

# Step 3: Save to .npy file
npy_path = 'people_counts.npy'
np.save(npy_path, labels)
print(f"Saved labels to .npy: {npy_path}")

# Step 4: Load images
img_path = 'D:/archive/images.npy'
img = np.load(img_path)  # shape: (num_samples, 480, 640, 3)
print(f"Shape of images array: {img.shape}")

# Step 5: Load the saved .npy labels
loaded_labels = np.load(npy_path)
print(f"Shape of labels array: {loaded_labels.shape}")

# Step 6: Quick check
print("First 10 labels:", loaded_labels[:10])

# Step 7: Labels statistics
labels_df = pd.DataFrame(loaded_labels, columns=['people'])
print("Labels Statistics Summary:")
print(labels_df.describe())

# ------------------------
# Load the Data
# ------------------------

# Load labels
label_df = pd.read_csv('people_counts.csv')
label_df.columns = ['id', 'people']  # Rename columns for clarity
print("Labels DataFrame head:")
display(label_df.head())

# Load images
img = np.load('D:/archive/images.npy')  # shape: (num_samples, 480, 640, 3)
print(f"Shape of images array: {img.shape}")

# Convert labels to numpy array
labels = np.array(label_df['people'])
print(f"Shape of labels array: {labels.shape}")

# Quick check
print("First 10 labels:", labels[:10])

# ------------------------
# Basic statistics
# ------------------------
labels_df = pd.DataFrame(labels, columns=['people'])

print("Labels Statistics Summary:")
display(labels_df.describe())

# ------------------------
#  Visualize distribution
# ------------------------
plt.figure(figsize=(12,6))
sns.distplot(labels, bins=30, color='purple', kde=True, hist=True)
plt.title('Distribution of Number of People in the Frames', fontsize=16)
plt.xlabel('Number of People', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.grid(True)
plt.show()

# ------------------------
#  Find Min and Max
# ------------------------
print(f"Minimum number of people in any frame: {labels.min()}")
print(f"Maximum number of people in any frame: {labels.max()}")

# ------------------------
#  Show some sample images
# ------------------------
import random

# Randomly pick 5 images
indices = random.sample(range(img.shape[0]), 5)

plt.figure(figsize=(18,5))
for i, idx in enumerate(indices):
    plt.subplot(1,5,i+1)
    plt.imshow(img[idx].astype('uint8'))
    plt.title(f"People: {labels[idx]}", fontsize=12)
    plt.axis('off')

plt.tight_layout()
plt.show()

import cv2
import random

# Load people counts
df = pd.read_csv('people_counts.csv')

# Display 5 random images with detection results
random_indices = random.sample(range(img.shape[0]), 5)

plt.figure(figsize=(20, 6))
for i, idx in enumerate(random_indices):
    image = img[idx].copy()
    results = model.predict(source=image, classes=[0], conf=0.25, imgsz=960, verbose=False)
    boxes = results[0].boxes.xyxy.cpu().numpy()

    # Draw red crosses on heads
    for (x1, y1, x2, y2) in boxes:
        center_x = int((x1 + x2) / 2)
        head_y = int(y1)
        cv2.line(image, (center_x - 10, head_y), (center_x + 10, head_y), (0, 0, 255), 2)
        cv2.line(image, (center_x, head_y - 10), (center_x, head_y + 10), (0, 0, 255), 2)

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    count = df[df['image_id'] == idx]['people_detected'].values[0]

    plt.subplot(1, 5, i + 1)
    plt.imshow(image_rgb)
    plt.title(f"People: {count}", fontsize=12)
    plt.axis('off')

plt.tight_layout()
plt.show()

# Binary classification based on mean value
threshold = 20
labels_class = np.where(labels > threshold, 1, 0)  # 1 = Crowded, 0 = Non-Crowded

# Quick check
unique, counts = np.unique(labels_class, return_counts=True)
print(dict(zip(unique, counts)))

import tensorflow as tf

# Resize images
img_resized = tf.image.resize(img, (224, 224)).numpy()
print(img_resized.shape)

img_resized = img_resized / 255.0

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(img_resized, labels_class, test_size=0.2, random_state=42, stratify=labels_class)

print(f"Training samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Create an ImageDataGenerator for augmentation
train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Apply only simple normalization to validation data (NO augmentation)
valid_datagen = ImageDataGenerator()

# Create train and validation generators
train_gen = train_datagen.flow(X_train, y_train, batch_size=32)
valid_gen = valid_datagen.flow(X_test, y_test, batch_size=32)

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')  # Output 0/1
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=15,
    callbacks=[early_stop],
    verbose=1
)

import matplotlib.pyplot as plt

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.grid(True)
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.grid(True)
plt.show()

# Evaluate the model on the test set
loss, accuracy = model.evaluate(valid_gen, verbose=1)

# Print the results
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models, Input
from tensorflow.keras.optimizers import Adam

# Define input layer
input_layer = Input(shape=(224, 224, 3))

# Load MobileNetV2 without the top layer
base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_layer)

# Freeze base model layers
base_model.trainable = False

# Add custom layers on top
x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.5)(x)
output_layer = layers.Dense(1, activation='sigmoid')(x)

# Build model
model_mobilenet = models.Model(inputs=input_layer, outputs=output_layer)

# Compile model
model_mobilenet.compile(optimizer=Adam(),
                        loss='binary_crossentropy',
                        metrics=['accuracy'])

# Print model summary
model_mobilenet.summary()

# Training MobileNetV2
history_mobilenet = model_mobilenet.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=30,
    callbacks=[early_stop],
    verbose=1
)

# Evaluate MobileNetV2
loss_mobilenet, accuracy_mobilenet = model_mobilenet.evaluate(valid_gen, verbose=1)
print(f"MobileNetV2 Test Loss: {loss_mobilenet:.4f}")
print(f"MobileNetV2 Test Accuracy: {accuracy_mobilenet:.4f}")

# Plot Loss curve for MobileNetV2
plt.figure(figsize=(12, 6))

# Plot training and validation loss
plt.subplot(1, 2, 1)
plt.plot(history_mobilenet.history['loss'], label='Train Loss')
plt.plot(history_mobilenet.history['val_loss'], label='Val Loss')
plt.title('MobileNetV2 - Loss Curve')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.grid(True)

# Plot training and validation accuracy
plt.subplot(1, 2, 2)
plt.plot(history_mobilenet.history['accuracy'], label='Train Accuracy')
plt.plot(history_mobilenet.history['val_accuracy'], label='Val Accuracy')
plt.title('MobileNetV2 - Accuracy Curve')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid(True)

plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix

# Generate predictions for classification report and confusion matrix
y_pred = []
y_true = []
for i in range(len(X_test) // batch_size):
    x_batch, y_batch = next(valid_gen)
    preds = model_mobilenet.predict(x_batch, verbose=0)
    y_pred.extend((preds >= 0.5).astype(int).flatten())
    y_true.extend(y_batch.astype(int))
y_pred = np.array(y_pred)
y_true = np.array(y_true)

# Classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=['Non-Crowded (0)', 'Crowded (1)']))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Crowded', 'Crowded'], yticklabels=['Non-Crowded', 'Crowded'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import cv2

# Function to load and preprocess the image
def load_and_preprocess_image(img_path, target_size=(224, 224)):
    img = image.load_img(img_path, target_size=target_size)  # Resize image to 224x224
    img_array = image.img_to_array(img)  # Convert image to array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)  # Preprocess the image
    return img_array

# Number of images to plot
num_images_to_plot = 5  # Set how many images you want to display

# Create a figure to plot multiple images
plt.figure(figsize=(20, 15))

# Loop through the images
for img_index in range(num_images_to_plot):
    # Generate the image filename
    img_filename = 'seq_' + str(label_df.iloc[img_index, 1]).zfill(6) + '.jpg'  # Zero-padding to match filename format

    # Construct the correct image path
    img_path = 'D:/archive/frames/frames/' + img_filename

    # Load and preprocess the image
    preprocessed_image = load_and_preprocess_image(img_path)

    # Predict the number of people in the image
    prediction = model_mobilenet.predict(preprocessed_image)

    # Round the prediction to get a binary label (Crowded: 1, Non-Crowded: 0)
    predicted_label = 'Crowded' if prediction >= 0.5 else 'Non-Crowded'

    # Get the actual label
    actual_label = 'Crowded' if labels[img_index] >= 31 else 'Non-Crowded'

    # Load the image for visualization
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for correct plotting

    # Plot the image
    plt.subplot(1, num_images_to_plot, img_index + 1)  # Create a subplot for each image
    plt.imshow(img)
    plt.title(f"Actual: {actual_label} | Predicted: {predicted_label}", fontsize=12)
    plt.axis('off')

plt.tight_layout()  # Adjust layout for better spacing
plt.show()

# Select 5 valid indices where images have valid dimensions
valid_indices = []
while len(valid_indices) < 5:
    idx = random.choice(range(img.shape[0]))
    if idx not in valid_indices:  # Avoid duplicates
        image = img[idx]
        if image.shape[0] > 0 and image.shape[1] > 0:
            valid_indices.append(idx)
        else:
            print(f"Skipping image {idx} with shape {image.shape}")

# Get selected images
selected_images = [img[idx] for idx in valid_indices]

# Preprocess images for model prediction (resize to 224x224 and normalize)
preprocessed_images = [tf.image.resize(image, (224, 224)).numpy() / 255.0 for image in selected_images]
preprocessed_images = np.array(preprocessed_images)

# Predict with model_mobilenet
predictions = model_mobilenet.predict(preprocessed_images)
predicted_labels = (predictions > 0.5).astype(int).flatten()

# Run YOLO on selected images
results_list = model.predict(source=selected_images, classes=[0], conf=0.25, imgsz=960, verbose=False)

# Calculate predicted people counts from YOLO detections
predicted_people = [len(results.boxes) for results in results_list]

# Function to draw red crosses on detected people
def draw_crosses(image, boxes):
    for (x1, y1, x2, y2) in boxes:
        center_x = int((x1 + x2) / 2)
        head_y = int(y1)  # Top of the bounding box (head)
        cv2.line(image, (center_x - 10, head_y), (center_x + 10, head_y), (0, 0, 255), 2)
        cv2.line(image, (center_x, head_y - 10), (center_x, head_y + 10), (0, 0, 255), 2)
    return image

# Mark people in each selected image
marked_images = []
for i, image in enumerate(selected_images):
    boxes = results_list[i].boxes.xyxy.cpu().numpy()
    marked_image = draw_crosses(image.copy(), boxes)
    marked_images.append(marked_image)

# Get actual people counts and compute actual labels
actual_people = [df.loc[df['image_id'] == idx, 'people_detected'].values[0] for idx in valid_indices]
actual_labels = [1 if count > threshold else 0 for count in actual_people]

# Display results
plt.figure(figsize=(20, 6))
for i in range(5):
    image_rgb = cv2.cvtColor(marked_images[i], cv2.COLOR_BGR2RGB)
    pred_status = "Crowded" if predicted_labels[i] == 1 else "Non-Crowded"
    actual_status = "Crowded" if actual_labels[i] == 1 else "Non-Crowded"
    title = f"Predicted: {pred_status}, People: {predicted_people[i]}\nActual: {actual_status}, People: {actual_people[i]}"

    plt.subplot(1, 5, i + 1)
    plt.imshow(image_rgb)
    plt.title(title, fontsize=12)
    plt.axis('off')

plt.tight_layout()
plt.show()

# Save the MobileNetV2 model
model_mobilenet.save('model_mobilenet.h5')
print("MobileNetV2 model saved to model_mobilenet.h5")

def draw_prominent_crosses(image, boxes):
    for (x1, y1, x2, y2) in boxes:
        # Calculate the center of the top of the bounding box (head position)
        center_x = int((x1 + x2) / 2)
        head_y = int(y1)  # Top of the bounding box (head)

        # Define cross size and thickness
        cross_size = 20  # Larger cross for prominence
        thickness = 3    # Thicker lines for visibility

        # Draw horizontal line
        cv2.line(image, (center_x - cross_size, head_y), (center_x + cross_size, head_y), (0, 0, 255), thickness)

        # Draw vertical line
        cv2.line(image, (center_x, head_y - cross_size), (center_x, head_y + cross_size), (0, 0, 255), thickness)

    return image

# Get image path from user
image_path = input("Enter the image path: ")
image = cv2.imread(image_path)

# Check if image is valid
if image is None or image.shape[0] == 0 or image.shape[1] == 0:
    print("Invalid image")
else:
    # Preprocess for MobileNet
    preprocessed_image = tf.image.resize(image, (224, 224)).numpy() / 255.0
    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)

    # Predict with MobileNet
    prediction = model_mobilenet.predict(preprocessed_image)[0][0]
    predicted_status = "Crowded" if prediction > 0.5 else "Non-Crowded"

    # Run YOLO
    results = model.predict(source=image, classes=[0], conf=0.25, imgsz=960, verbose=False)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    predicted_count = len(boxes)

    # Mark the image with prominent crosses
    marked_image = draw_prominent_crosses(image.copy(), boxes)

    # Convert to RGB for display
    image_rgb = cv2.cvtColor(marked_image, cv2.COLOR_BGR2RGB)

    # Display the result
    plt.imshow(image_rgb)
    plt.title(f"Predicted: {predicted_status}, People: {predicted_count}")
    plt.axis('off')
    plt.show()